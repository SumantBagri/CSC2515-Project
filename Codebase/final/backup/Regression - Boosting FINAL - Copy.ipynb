{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5afa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from scipy.stats import ttest_rel\n",
    "import math\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438f9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(name):\n",
    "    directory = os.path.dirname(name)\n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716666e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_parameters_regression(dataset_name, alg='sgb', n_splits=1):\n",
    "\n",
    "    # load and prepare data\n",
    "    data_dir = os.path.join('datasets', dataset_name)\n",
    "    train_file = os.path.join(data_dir, 'train')\n",
    "    validation_file = os.path.join(data_dir, 'validation')\n",
    "    cd_file = os.path.join(data_dir, 'pool.cd')\n",
    "    \n",
    "    train_pool = Pool(data=train_file, column_description=cd_file)\n",
    "    validation_pool = Pool(data=validation_file, column_description=cd_file)\n",
    "    \n",
    "\n",
    "    params = []\n",
    "    seed = 1000 # starting random seed for hyperparameter tuning\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "    \n",
    "        # list of hyperparameters for grid search\n",
    "        depths = [3, 4, 5, 6] # tree depth\n",
    "        lrs = [0.001, 0.01, 0.1] # learning rate \n",
    "        if alg == \"sgb\" or alg == \"sglb\": # by default, we tune sample rate\n",
    "            samples = [0.25, 0.5, 0.75]\n",
    "        if alg == \"sgb-fixed\": # sgb without sample rate tuning\n",
    "            samples = [0.5]\n",
    "        if alg == \"sglb-fixed\": # sglb without sample rate tuning\n",
    "            samples = [1.0]\n",
    "        shape = (len(depths), len(lrs), len(samples))\n",
    "\n",
    "        results = np.zeros(shape)\n",
    "        \n",
    "        # perform grid search\n",
    "        for d, depth in enumerate(depths):\n",
    "            for l, lr in enumerate(lrs):\n",
    "                for s, sample in enumerate(samples):\n",
    "                    if alg == 'sgb' or alg == 'sgb-fixed':\n",
    "                            model = CatBoostRegressor(loss_function='RMSEWithUncertainty',\n",
    "                                                      learning_rate=lr, depth=depth, \n",
    "                                                      subsample=sample, bootstrap_type='Bernoulli', verbose=False, \n",
    "                                                      random_seed=seed)                      \n",
    "                    if alg == 'sglb' or alg == 'sglb-fixed':\n",
    "                        model = CatBoostRegressor(loss_function='RMSEWithUncertainty',\n",
    "                                                  learning_rate=lr, depth=depth, \n",
    "                                                  subsample=sample, \n",
    "                                                  bootstrap_type='Bernoulli', \n",
    "                                                  verbose=False, random_seed=seed, posterior_sampling=True,\n",
    "                                                 allow_writing_files=False)\n",
    "\n",
    "                    model.fit(train_pool, eval_set=validation_pool, use_best_model=False)\n",
    "\n",
    "                # compute nll\n",
    "                results[d, l, s] = model.evals_result_['validation']['RMSEWithUncertainty'][-1]\n",
    "\n",
    "                seed += 1 # update seed\n",
    "\n",
    "        # get best parameters\n",
    "        argmin = np.unravel_index(np.argmin(results), shape)\n",
    "        depth = depths[argmin[0]]\n",
    "        lr = lrs[argmin[1]]\n",
    "        sample = samples[argmin[2]]\n",
    "\n",
    "        current_params = {'depth': depth, 'lr': lr, 'sample': sample}\n",
    "        params.append(current_params)\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6761c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_regression(dataset_name, params, alg=\"sgb\", num_models=10, n_splits=1):\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        \n",
    "        # load and prepare data\n",
    "        data_dir = os.path.join('datasets', dataset_name)\n",
    "        full_train_file = os.path.join(data_dir, 'full_train')\n",
    "        test_file = os.path.join(data_dir, 'test')\n",
    "        cd_file = os.path.join(data_dir, 'pool.cd')\n",
    "\n",
    "        full_train_pool = Pool(data=full_train_file, column_description=cd_file)\n",
    "        test_pool = Pool(data=test_file, column_description=cd_file)\n",
    "\n",
    "        # params contains optimal parameters for each fold\n",
    "        depth = params[fold]['depth']\n",
    "        lr = params[fold]['lr']\n",
    "        sample = params[fold]['sample']\n",
    "\n",
    "        seed = 10 * fold # fix different starting random seeds for all folds\n",
    "        for i in range(num_models):\n",
    "            if alg == 'sgb' or alg == 'sgb-fixed':\n",
    "                    model = CatBoostRegressor(loss_function='RMSEWithUncertainty', verbose=False, \n",
    "                                              learning_rate=lr, depth=depth, subsample=sample,\n",
    "                                              bootstrap_type='Bernoulli', custom_metric='RMSE', \n",
    "                                              random_seed=seed)   \n",
    "            if alg == 'sglb' or alg == 'sglb-fixed':\n",
    "                model = CatBoostRegressor(loss_function='RMSEWithUncertainty', verbose=False, \n",
    "                                          learning_rate=lr, depth=depth, subsample=sample, \n",
    "                                          bootstrap_type='Bernoulli', posterior_sampling=True, \n",
    "                                          custom_metric='RMSE', random_seed=seed, \n",
    "                                         allow_writing_files=False) #, task_type=\"GPU\", devices='0')\n",
    "            seed += 1 # new seed for each ensemble element        \n",
    "\n",
    "            model.fit(full_train_pool, eval_set=test_pool, use_best_model=False) # do not use test pool for choosing best iteration\n",
    "            model.save_model(\"results/models/\" + dataset_name + \"_\" + alg + \"_f\" + str(fold) + \"_\" + str(i), format=\"cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af585a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tRegression - Boosting: Generating models..\n",
      "Dataset = parkinsons\n",
      "Tuning hyperparameters...\n",
      "\tAlgorithm =  sgb-fixed\n",
      "\tAlgorithm =  sglb-fixed\n",
      "Training models...\n",
      "\tAlgorithm =  sgb-fixed\n",
      "\tAlgorithm =  sglb-fixed\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "tuning = 1  # Change to 1 for tuning hyperparameters\n",
    "\n",
    "datasets = [\"parkinsons\"] \n",
    "\n",
    "algorithms = ['sgb-fixed', 'sglb-fixed'] \n",
    "\n",
    "print('\\t\\t\\tRegression - Boosting: Generating models..')\n",
    "for name in datasets:\n",
    "    print(\"Dataset =\", name)\n",
    "\n",
    "    if tuning == 1:\n",
    "        create_dir(\"results/params\")\n",
    "\n",
    "        # Tune hyperparameters\n",
    "        print(\"Tuning hyperparameters...\")\n",
    "        for alg in algorithms:\n",
    "            print('\\tAlgorithm = ', alg)\n",
    "            params = tune_parameters_regression(name, alg=alg)\n",
    "            with open(\"results/params/\" + name + \"_\" + alg + '.json', 'w') as fp:\n",
    "                json.dump(params, fp)\n",
    "\n",
    "    # Training models\n",
    "    print(\"Training models...\")\n",
    "    create_dir(\"results/models\")\n",
    "\n",
    "    for alg in algorithms:\n",
    "        print('\\tAlgorithm = ', alg)\n",
    "        with open(\"results/params/\" + name + \"_\" + alg + '.json', 'r') as fp:\n",
    "            params = json.load(fp)\n",
    "        generate_ensemble_regression(name, params, alg=alg)\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752b8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48593283",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01454a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4afe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prr_regression(targets, preds, measure, pos_label=1):\n",
    "    if pos_label != 1:\n",
    "        measure_loc = -1.0 * measure\n",
    "    else:\n",
    "        measure_loc = measure\n",
    "    preds = np.squeeze(preds)\n",
    "    # Compute total MSE\n",
    "    error = (preds - targets) ** 2\n",
    "    MSE_0 = np.mean(error)\n",
    "    # print 'BASE MSE', MSE_0\n",
    "\n",
    "    # Create array\n",
    "    array = np.concatenate(\n",
    "        (preds[:, np.newaxis], targets[:, np.newaxis], error[:, np.newaxis], measure_loc[:, np.newaxis]), axis=1)\n",
    "\n",
    "    # Results arrays\n",
    "    results_max = [[0.0, 0.0]]\n",
    "    results_var = [[0.0, 0.0]]\n",
    "    results_min = [[0.0, 0.0]]\n",
    "\n",
    "    optimal_ranking = array[:, 2].argsort()\n",
    "    sorted_array = array[optimal_ranking]  # Sort by error\n",
    "\n",
    "    for i in range(1, array.shape[0]):\n",
    "        x = np.concatenate((sorted_array[:-i, 0], sorted_array[-i:, 1]), axis=0)\n",
    "        mse = np.mean((x - sorted_array[:, 1]) ** 2)\n",
    "        # Best rejection\n",
    "        results_max.append([float(i) / float(array.shape[0]), (MSE_0 - mse) / MSE_0])\n",
    "        # Random Rejection\n",
    "        results_min.append([float(i) / float(array.shape[0]), float(i) / float(array.shape[0])])\n",
    "\n",
    "    uncertainty_ranking = array[:, 3].argsort()\n",
    "    sorted_array = array[uncertainty_ranking]  # Sort by uncertainty\n",
    "\n",
    "    for i in range(1, array.shape[0]):\n",
    "        x = np.concatenate((sorted_array[:-i, 0], sorted_array[-i:, 1]), axis=0)\n",
    "        mse = np.mean((x - sorted_array[:, 1]) ** 2)\n",
    "        results_var.append([float(i) / float(array.shape[0]), (MSE_0 - mse) / MSE_0])\n",
    "\n",
    "    max_auc = auc([x[0] for x in results_max], [x[1] for x in results_max])\n",
    "    var_auc = auc([x[0] for x in results_var], [x[1] for x in results_var])\n",
    "    min_auc = auc([x[0] for x in results_min], [x[1] for x in results_min])\n",
    "\n",
    "    AUC_RR = (var_auc - min_auc) / (max_auc - min_auc)\n",
    "\n",
    "    return AUC_RR\n",
    "\n",
    "def nll_regression(target, mu, var, epsilon=1e-8, raw=False):\n",
    "    nll = (target - mu)**2 / (2.0 * var + epsilon) + np.log(var + epsilon) / 2.0 + np.log(2 * np.pi) / 2.0\n",
    "    if raw: # for individual predictions\n",
    "        return nll\n",
    "    return np.mean(nll)\n",
    "\n",
    "def ens_nll_regression(target, preds, epsilon=1e-8, raw=False):\n",
    "    mu = preds[:, :, 0]\n",
    "    var = preds[:, :, 1]\n",
    "    nll = (target - mu)**2 / (2.0 * var + epsilon) + np.log(var + epsilon) / 2.0 + np.log(2 * np.pi) / 2.0\n",
    "    proba = np.exp (-1 * nll)\n",
    "    if raw: # for individual predictions\n",
    "        return -1 * np.log(np.mean(proba, axis=0)) # for individual predictions\n",
    "    return np.mean(-1 * np.log(np.mean(proba, axis=0)))\n",
    "\n",
    "def ood_detect(domain_labels, in_measure, out_measure, mode, pos_label=1):\n",
    "    scores = np.concatenate((in_measure, out_measure), axis=0)\n",
    "    scores = np.asarray(scores, dtype=np.longdouble)\n",
    "    if pos_label != 1:\n",
    "        scores *= -1.0\n",
    "\n",
    "    if mode == 'PR':\n",
    "        precision, recall, thresholds = precision_recall_curve(domain_labels, scores)\n",
    "        aupr = auc(recall, precision)\n",
    "        return aupr\n",
    "\n",
    "    elif mode == 'ROC':\n",
    "        roc_auc = roc_auc_score(domain_labels, scores)\n",
    "        return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e02e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_KL(params1, params2, epsilon=1e-20):\n",
    "    mu_1 = params1[0]\n",
    "    mu_2 = params2[0]\n",
    "\n",
    "    logvar1 = np.log(params1[1] + epsilon)\n",
    "    logvar2 = np.log(params2[1] + epsilon)\n",
    "\n",
    "    mean_term = 0.5 * np.exp(2 * np.log(np.abs(mu_1 - mu_2)) - logvar2)\n",
    "    sigma_term = 0.5 * (np.exp(logvar1 - logvar2) - 1.0 + logvar2 - logvar1)\n",
    "\n",
    "    return mean_term + sigma_term\n",
    "\n",
    "def epkl_reg(preds):\n",
    "    \"\"\"\n",
    "    preds: array [n_samples, n_models, 2]\n",
    "    \"\"\"\n",
    "    M = preds.shape[1]\n",
    "    EPKL = []\n",
    "    for pred in preds:\n",
    "        epkl = 0.0\n",
    "        for i, pr1 in enumerate(pred):\n",
    "            for j, pr2 in enumerate(pred):\n",
    "                if i != j:\n",
    "                    epkl += normal_KL(pr1, pr2)\n",
    "\n",
    "        epkl = epkl / (M * (M - 1))\n",
    "        EPKL.append(epkl)\n",
    "    return np.asarray(EPKL)\n",
    "\n",
    "def ensemble_uncertainties_regression(preds):\n",
    "    \"\"\"\n",
    "    preds: array [n_samples, n_models, 2] - last dim ins mean, var\n",
    "    \"\"\"\n",
    "    epkl = epkl_reg(preds)\n",
    "\n",
    "    var_mean = np.var(preds[:, :, 0], axis=1)\n",
    "    mean_var = np.mean(preds[:, :, 1], axis=1)\n",
    "\n",
    "    uncertainty = {'tvar': var_mean + mean_var,\n",
    "                   'mvar': mean_var,\n",
    "                   'varm': var_mean,\n",
    "                   'epkl': epkl}\n",
    "\n",
    "    return uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bf1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(preds, target, raw=False):\n",
    "    if raw:\n",
    "        return (preds - target)**2 # for individual predictions\n",
    "    return np.sqrt(np.mean((preds - target)**2))\n",
    "\n",
    "def ens_rmse(target, preds, epsilon=1e-8, raw=False):\n",
    "    means = preds[:, :, 0] \n",
    "    avg_mean = np.mean(means, axis=0) \n",
    "    if raw: # for individual predictions\n",
    "        return calc_rmse(avg_mean, target, raw=True)\n",
    "    return calc_rmse(avg_mean, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37561b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_predict(X, name, alg, fold, i):\n",
    "    model = CatBoostRegressor()\n",
    "    model.load_model(\"results/models/\" + name + \"_\" + alg + \"_f\" + str(fold) + \"_\" + str(i)) \n",
    "    preds = model.predict(X)\n",
    "    return preds, model\n",
    "    \n",
    "def predict(X, model, alg):\n",
    "    preds = model.predict(X)\n",
    "    if alg == \"rf\":\n",
    "        preds = np.array([(p, 1) for p in preds])\n",
    "    return preds\n",
    "            \n",
    "def aggregate_results(name, modes = [\"single\", \"ens\"], \n",
    "                      algorithms = ['sgb-fixed', 'sglb-fixed'], num_models = 10, \n",
    "                      raw=False):\n",
    "    \n",
    "    n_splits=1\n",
    "    if name != 'parkinsons':\n",
    "        X, y, index_train, index_test, n_splits = load_regression_dataset(name)\n",
    "    \n",
    "    results = [] # metric values for all algorithms and all folds\n",
    "    \n",
    "    # for ood evaluation\n",
    "    ood_X_test = np.loadtxt(\"datasets/ood/\" + name)\n",
    "    if name == \"naval-propulsion-plant\":\n",
    "        ood_X_test = ood_X_test[:, :-1]\n",
    "    ood_size = len(ood_X_test)\n",
    "        \n",
    "    for mode in modes:\n",
    "        for alg in algorithms:\n",
    "        \n",
    "            values = defaultdict(lambda: []) # metric values for all folds for given algorithm\n",
    "\n",
    "            for fold in range(n_splits):\n",
    "\n",
    "                ood_test_pool = Pool(data=\"datasets/ood/\" + name, column_description=\"datasets/\"+name+\"/pool.cd\")\n",
    "                X_test, y_test = ood_test_pool.get_features(), ood_test_pool.get_label()\n",
    "                y_test = np.array(y_test).astype(np.float64)\n",
    "                \n",
    "                test_size = len(X_test)\n",
    "                domain_labels = np.concatenate([np.zeros(test_size), np.ones(ood_size)])\n",
    "\n",
    "                if mode == \"single\":\n",
    "                    # use 0th model from ensemble as a single model\n",
    "                    preds, model = load_and_predict(X_test, name, alg, fold, 0)\n",
    "\n",
    "                    values[\"rmse\"].append(calc_rmse(preds[:, 0], y_test, raw=raw))\n",
    "                    values[\"nll\"].append(nll_regression(y_test, preds[:, 0], preds[:, 1], raw=raw))\n",
    "                    values[\"TU_prr\"].append(prr_regression(y_test, preds[:, 0], preds[:, 1]))\n",
    "                    values[\"KU_prr\"].append(float(\"nan\"))\n",
    "                    values[\"KU_auc\"].append(float(\"nan\"))\n",
    "                    \n",
    "                    ood_preds = predict(ood_X_test, model, alg)\n",
    "                    in_measure = preds[:, 1]\n",
    "                    out_measure = ood_preds[:, 1]\n",
    "                    values[\"TU_auc\"].append(ood_detect(domain_labels, in_measure, out_measure, mode=\"ROC\"))\n",
    "\n",
    "                if mode == \"ens\":\n",
    "                    all_preds = [] # predictions of all models in ensemble\n",
    "                    all_preds_ood = []\n",
    "                    \n",
    "                    for i in range(num_models):\n",
    "                        preds, model = load_and_predict(X_test, name, alg, fold, i)\n",
    "                        all_preds.append(preds)\n",
    "                        preds = predict(ood_X_test, model, alg)\n",
    "                        all_preds_ood.append(preds)   \n",
    "                    all_preds = np.array(all_preds)\n",
    "                    \n",
    "                    values[\"rmse\"].append(ens_rmse(y_test, all_preds, raw=raw))\n",
    "                    values[\"nll\"].append(ens_nll_regression(y_test, all_preds, raw=raw)) \n",
    "                    \n",
    "                    TU = ensemble_uncertainties_regression(np.swapaxes(all_preds, 0, 1))[\"tvar\"]\n",
    "                    KU = ensemble_uncertainties_regression(np.swapaxes(all_preds, 0, 1))[\"varm\"]\n",
    "\n",
    "                    mean_preds = np.mean(all_preds[:, :, 0], axis=0)\n",
    "\n",
    "                    values[\"TU_prr\"].append(prr_regression(y_test, mean_preds, TU))\n",
    "                    values[\"KU_prr\"].append(prr_regression(y_test, mean_preds, KU))\n",
    "                    \n",
    "                    all_preds_ood = np.array(all_preds_ood)\n",
    "                    TU_ood = ensemble_uncertainties_regression(np.swapaxes(all_preds_ood, 0, 1))[\"tvar\"]\n",
    "                    KU_ood = ensemble_uncertainties_regression(np.swapaxes(all_preds_ood, 0, 1))[\"varm\"]\n",
    "                    values[\"TU_auc\"].append(ood_detect(domain_labels, TU, TU_ood, mode=\"ROC\"))\n",
    "                    values[\"KU_auc\"].append(ood_detect(domain_labels, KU, KU_ood, mode=\"ROC\"))\n",
    "            \n",
    "            results.append(values)\n",
    "\n",
    "    return np.array(results)\n",
    "    \n",
    "def make_table(values):\n",
    "    prr_TU = np.array([values[i][\"TU_prr\"] for i in range(len(values))])\n",
    "    auc_TU = np.array([values[i][\"TU_auc\"] for i in range(len(values))])\n",
    "    TU = np.concatenate((np.squeeze(prr_TU), np.squeeze(auc_TU)), axis=0)\n",
    "\n",
    "    prr_KU = np.array([values[i][\"KU_prr\"] for i in range(len(values))])\n",
    "    auc_KU = np.array([values[i][\"KU_auc\"] for i in range(len(values))])\n",
    "    KU = np.concatenate((np.squeeze(prr_KU), np.squeeze(auc_KU)), axis=0)\n",
    "\n",
    "    df = pd.DataFrame(100*np.abs(np.stack((TU, KU))), index=['TU', 'KU']) \n",
    "    columns=[('PRR%', 'Single','SGB'),('PRR%', 'Single','SGLB'), ('PRR%', 'Ensemble','SGB'),('PRR%', 'Ensemble','SGLB'), \n",
    "             ('AUC-ROC%', 'Single','SGB'),('AUC-ROC%', 'Single','SGLB'), ('AUC-ROC%', 'Ensemble','SGB'),('AUC-ROC%', 'Ensemble','SGLB')]\n",
    "    df.columns=pd.MultiIndex.from_tuples(columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cec36aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tRegression - Boosting\n",
      "\t\t\t===PRR and AUC-ROC Table===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">PRR%</th>\n",
       "      <th colspan=\"4\" halign=\"left\">AUC-ROC%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Single</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ensemble</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Single</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ensemble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TU</th>\n",
       "      <td>15.0035</td>\n",
       "      <td>49.905147</td>\n",
       "      <td>6.306624</td>\n",
       "      <td>15.207253</td>\n",
       "      <td>99.828115</td>\n",
       "      <td>97.244174</td>\n",
       "      <td>87.609698</td>\n",
       "      <td>64.345403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KU</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.364925</td>\n",
       "      <td>13.438849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.846669</td>\n",
       "      <td>59.135770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRR%                                    AUC-ROC%                        \\\n",
       "     Single              Ensemble                Single              Ensemble   \n",
       "        SGB       SGLB        SGB       SGLB        SGB       SGLB        SGB   \n",
       "TU  15.0035  49.905147   6.306624  15.207253  99.828115  97.244174  87.609698   \n",
       "KU      NaN        NaN  11.364925  13.438849        NaN        NaN  84.846669   \n",
       "\n",
       "               \n",
       "               \n",
       "         SGLB  \n",
       "TU  64.345403  \n",
       "KU  59.135770  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'parkinsons'\n",
    "\n",
    "print('\\t\\t\\tRegression - Boosting')\n",
    "print(\"\\t\\t\\t===PRR and AUC-ROC Table===\")\n",
    " \n",
    "values = aggregate_results(dataset, raw=False)\n",
    "\n",
    "make_table(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72640ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
