{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809739c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from catboost.utils import read_cd\n",
    "from sklearn.metrics import zero_one_loss, log_loss, roc_auc_score, precision_recall_curve, auc\n",
    "from scipy.stats import ttest_rel\n",
    "import math\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55846b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(name):\n",
    "    directory = os.path.dirname(name)\n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d27c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_parameters_classification(dataset_name, alg='sgb'):\n",
    "\n",
    "    # load and prepare data\n",
    "    data_dir = os.path.join('datasets', dataset_name)\n",
    "    train_file = os.path.join(data_dir, 'train')\n",
    "    validation_file = os.path.join(data_dir, 'validation')\n",
    "    cd_file = os.path.join(data_dir, 'pool.cd')\n",
    "    \n",
    "    train_pool = Pool(data=train_file, column_description=cd_file)\n",
    "    validation_pool = Pool(data=validation_file, column_description=cd_file)    \n",
    "\n",
    "    seed = 1000 # starting random seed for hyperparameter tuning\n",
    "    \n",
    "    # list of hyperparameters for grid search\n",
    "    depths = [3, 4, 5, 6] # tree depth\n",
    "    lrs = [0.001, 0.01, 0.1] # learning rate \n",
    "    \n",
    "    if alg == \"sgb\" or alg == \"sglb\": # by default, we tune sample rate\n",
    "        samples = [0.25, 0.5, 0.75]\n",
    "    if alg == \"sgb-fixed\": # sgb without sample rate tuning\n",
    "        samples = [0.5]\n",
    "    if alg == \"sglb-fixed\": # sglb without sample rate tuning\n",
    "        samples = [1.0]\n",
    "    shape = (len(depths), len(lrs), len(samples))\n",
    "\n",
    "    results = np.zeros(shape)\n",
    "    \n",
    "    # perform grid search\n",
    "    for d, depth in enumerate(depths):\n",
    "        for l, lr in enumerate(lrs):\n",
    "            for s, sample in enumerate(samples):\n",
    "                if alg == 'sgb' or alg == 'sgb-fixed':\n",
    "                    model = CatBoostClassifier(loss_function='Logloss',learning_rate=lr, depth=depth, subsample=sample, bootstrap_type='Bernoulli', verbose=False, random_seed=seed)                      \n",
    "                if alg == 'sglb' or alg == 'sglb-fixed':\n",
    "                    model = CatBoostClassifier(loss_function='Logloss',learning_rate=lr, depth=depth, subsample=sample, bootstrap_type='Bernoulli', verbose=False, random_seed=seed, posterior_sampling=True)\n",
    "                    \n",
    "                model.fit(train_pool, eval_set=validation_pool, use_best_model=False)\n",
    "                results[d, l, s] = model.evals_result_['validation']['Logloss'][-1]\n",
    "                    \n",
    "                seed += 1 # update seed\n",
    "        \n",
    "    # get best parameters\n",
    "    argmin = np.unravel_index(np.argmin(results), shape)\n",
    "    depth = depths[argmin[0]]\n",
    "    lr = lrs[argmin[1]]\n",
    "    sample = samples[argmin[2]]\n",
    "        \n",
    "    params = {'depth': depth, 'lr': lr, 'sample': sample}\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8c5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_classification(dataset_name, params, alg=\"sgb\", num_models=10):\n",
    "\n",
    "    # load and prepare data\n",
    "    data_dir = os.path.join('datasets', dataset_name)\n",
    "    full_train_file = os.path.join(data_dir, 'full_train')\n",
    "    test_file = os.path.join(data_dir, 'test')\n",
    "    cd_file = os.path.join(data_dir, 'pool.cd')\n",
    "    \n",
    "    full_train_pool = Pool(data=full_train_file, column_description=cd_file)\n",
    "    test_pool = Pool(data=test_file, column_description=cd_file)\n",
    "\n",
    "    # parameters\n",
    "    depth = params['depth']\n",
    "    lr = params['lr']\n",
    "    sample = params['sample']\n",
    "        \n",
    "    seed = 0\n",
    "    for i in range(num_models):\n",
    "        if alg == 'sgb' or alg == 'sgb-fixed':\n",
    "            model = CatBoostClassifier(loss_function='Logloss', verbose=False, \n",
    "                                       learning_rate=lr, depth=depth, subsample=sample,\n",
    "                                       bootstrap_type='Bernoulli', custom_metric='ZeroOneLoss', \n",
    "                                       random_seed=seed)   \n",
    "        if alg == 'sglb' or alg == 'sglb-fixed':\n",
    "            model = CatBoostClassifier(loss_function='Logloss', verbose=False, \n",
    "                                       learning_rate=lr, depth=depth, subsample=sample, \n",
    "                                       bootstrap_type='Bernoulli', posterior_sampling=True, \n",
    "                                       custom_metric='ZeroOneLoss', random_seed=seed)\n",
    "        seed += 1 # new seed for each ensemble element\n",
    "\n",
    "        model.fit(full_train_pool, eval_set=test_pool, use_best_model=False) # do not use test pool for choosing best iteration\n",
    "        model.save_model(\"results/models/\" + dataset_name + \"_\" + alg + \"_\" + str(i), format=\"cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30df3b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating models..\n",
      "Dataset = credit\n",
      "Tuning hyperparameters...\n",
      "Algorithm =  sgb-fixed\n",
      "Algorithm =  sglb-fixed\n",
      "Training models...\n",
      "Algorithm =  sgb-fixed\n",
      "Algorithm =  sglb-fixed\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "tuning = 1  # Change to 1 for tuning hyperparameters\n",
    "\n",
    "datasets = [\"credit\"] \n",
    "\n",
    "algorithms = ['sgb-fixed', 'sglb-fixed'] \n",
    "\n",
    "print('Classification - Boosting: Generating models..')\n",
    "for name in datasets:\n",
    "    print(\"Dataset =\", name)\n",
    "\n",
    "    if tuning == 1:\n",
    "        create_dir(\"results/params\")\n",
    "\n",
    "        # Tune hyperparameters\n",
    "        print(\"Tuning hyperparameters...\")\n",
    "        for alg in algorithms:\n",
    "            print('Algorithm = ', alg)\n",
    "            params = tune_parameters_classification(name, alg=alg)\n",
    "            with open(\"results/params/\" + name + \"_\" + alg + '.json', 'w') as fp:\n",
    "                json.dump(params, fp)\n",
    "\n",
    "    # Training all models\n",
    "    print(\"Training models...\")\n",
    "    create_dir(\"results/models\")\n",
    "    for alg in algorithms:\n",
    "        print('Algorithm = ', alg)\n",
    "        with open(\"results/params/\" + name + \"_\" + alg + '.json', 'r') as fp:\n",
    "            params = json.load(fp)\n",
    "        generate_ensemble_classification(name, params, alg=alg)\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553ca14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1db0258",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12da94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a441f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_classification_dataset(name):\n",
    "    # converting categorical features to numerical\n",
    "\n",
    "    data_dir = os.path.join('datasets', name)\n",
    "    train_file = os.path.join(data_dir, 'full_train')\n",
    "    test_file = os.path.join(data_dir, 'test')\n",
    "    cd_file = os.path.join(data_dir, 'pool.cd')\n",
    "\n",
    "    train = np.loadtxt(train_file, delimiter=\"\\t\", dtype=\"object\")\n",
    "    test = np.loadtxt(test_file, delimiter=\"\\t\", dtype=\"object\")\n",
    "    cd = read_cd(cd_file, data_file=train_file)\n",
    "\n",
    "    # Target can be called 'Label' or 'Target' in pool.cd\n",
    "    try:\n",
    "        label_ind = cd['column_type_to_indices']['Label']\n",
    "    except:\n",
    "        label_ind = cd['column_type_to_indices']['Target']\n",
    "\n",
    "    np.random.seed(42)  # fix random seed\n",
    "    train = np.random.permutation(train)\n",
    "\n",
    "    y_train = train[:, label_ind]\n",
    "    y_train = y_train.reshape(-1)\n",
    "\n",
    "    y_test = test[:, label_ind]\n",
    "    y_test = y_test.reshape(-1)\n",
    "\n",
    "    cat_features = cd['column_type_to_indices']['Categ']  # features to be replaced\n",
    "\n",
    "    enc = LeaveOneOutEncoder(cols=cat_features, return_df=False, random_state=10, sigma=0.3)\n",
    "\n",
    "    transformed_train = enc.fit_transform(train, y_train).astype(\"float64\")\n",
    "    X_train = np.delete(transformed_train, label_ind, 1)  # remove target column\n",
    "\n",
    "    transformed_test = enc.transform(test).astype(\"float64\")\n",
    "    X_test = np.delete(transformed_test, label_ind, 1)  # remove target column\n",
    "\n",
    "    return np.nan_to_num(X_train), y_train, np.nan_to_num(X_test), y_test, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9123c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prr_class(labels, probs, measure, rev: bool):\n",
    "    # Get predictions\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "\n",
    "    if rev:\n",
    "        inds = np.argsort(measure)[::-1]\n",
    "    else:\n",
    "        inds = np.argsort(measure)\n",
    "\n",
    "    total_data = np.float64(preds.shape[0])\n",
    "    errors, percentages = [], []\n",
    "\n",
    "    for i in range(preds.shape[0]):\n",
    "        errors.append(np.sum(\n",
    "            np.asarray(labels[inds[:i]] != preds[inds[:i]], dtype=np.float32)) * 100.0 / total_data)\n",
    "        percentages.append(float(i + 1) / total_data * 100.0)\n",
    "    errors, percentages = np.asarray(errors)[:, np.newaxis], np.asarray(percentages)\n",
    "\n",
    "    base_error = errors[-1]\n",
    "    n_items = errors.shape[0]\n",
    "    \n",
    "    auc_uns = 1.0 - auc(percentages / 100.0, errors[::-1] / 100.0)\n",
    "\n",
    "    random_rejection = np.asarray(\n",
    "        [base_error * (1.0 - float(i) / float(n_items)) for i in range(n_items)],\n",
    "        dtype=np.float32)\n",
    "    auc_rnd = 1.0 - auc(percentages / 100.0, random_rejection / 100.0)\n",
    "    orc_rejection = np.asarray(\n",
    "        [base_error * (1.0 - float(i) / float(base_error / 100.0 * n_items)) for i in\n",
    "         range(int(base_error / 100.0 * n_items))], dtype=np.float32)\n",
    "    orc = np.zeros_like(errors)\n",
    "    orc[0:orc_rejection.shape[0]] = orc_rejection\n",
    "    auc_orc = 1.0 - auc(percentages / 100.0, orc / 100.0)\n",
    "\n",
    "    rejection_ratio = (auc_uns - auc_rnd) / (auc_orc - auc_rnd) * 100.0\n",
    "    return rejection_ratio\n",
    "\n",
    "def ood_detect(domain_labels, in_measure, out_measure, mode, pos_label=1):\n",
    "    scores = np.concatenate((in_measure, out_measure), axis=0)\n",
    "    scores = np.asarray(scores, dtype=np.longdouble)\n",
    "    if pos_label != 1:\n",
    "        scores *= -1.0\n",
    "\n",
    "    if mode == 'PR':\n",
    "        precision, recall, thresholds = precision_recall_curve(domain_labels, scores)\n",
    "        aupr = auc(recall, precision)\n",
    "        return aupr\n",
    "\n",
    "    elif mode == 'ROC':\n",
    "        roc_auc = roc_auc_score(domain_labels, scores)\n",
    "        return roc_auc\n",
    "\n",
    "def nll_class(target, probs, epsilon=1e-10):\n",
    "    log_p = -np.log(probs + epsilon)\n",
    "    return target*log_p[:, 1] + (1-target)*log_p[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4fce6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probs, epsilon=1e-10):\n",
    "    log_probs = -np.log(probs + epsilon)\n",
    "    return np.sum(probs * log_probs, axis=1)\n",
    "\n",
    "def entropy_of_expected_class(probs, epsilon=1e-10):\n",
    "    mean_probs = np.mean(probs, axis=0)\n",
    "    log_probs = -np.log(mean_probs + epsilon)\n",
    "    return np.sum(mean_probs * log_probs, axis=1)\n",
    "\n",
    "\n",
    "def expected_entropy_class(probs, epsilon=1e-10):\n",
    "    log_probs = -np.log(probs + epsilon)\n",
    "\n",
    "    return np.mean(np.sum(probs * log_probs, axis=2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f6fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "     \n",
    "def load_model(name, alg, i):\n",
    "    if alg == \"rf\":\n",
    "        model = joblib.load(\"results/models/\" + name + \"_\" + alg + \"_\" + str(i))\n",
    "    else:\n",
    "        model = CatBoostClassifier()\n",
    "        model.load_model(\"results/models/\" + name + \"_\" + alg + \"_\" + str(i)) \n",
    "    return model\n",
    "\n",
    "def normalize_test_labels(y_test):\n",
    "    y_test_norm = []\n",
    "    c0 = min(y_test)\n",
    "    for y in y_test:\n",
    "        if y == c0:\n",
    "            y_test_norm.append(0)\n",
    "        else:\n",
    "            y_test_norm.append(1)\n",
    "    return np.array(y_test_norm)\n",
    "            \n",
    "def aggregate_results(name, modes = [\"single\", \"ens\"], algorithms = ['sgb-fixed', 'sglb-fixed'], num_models = 10):\n",
    "    \n",
    "    results = [] # metric values for all algorithms and all folds\n",
    "        \n",
    "    for mode in modes:\n",
    "        for alg in algorithms:\n",
    "            \n",
    "            test_pool = Pool(data=\"datasets/\"+name+\"/test\", column_description=\"datasets/\"+name+\"/pool.cd\")\n",
    "            ood_test_pool = Pool(data=\"datasets/ood/\" + name, column_description=\"datasets/\"+name+\"/pool.cd\")\n",
    "            ood_size = ood_test_pool.num_row()\n",
    "\n",
    "            y_test = test_pool.get_label()\n",
    "            \n",
    "            test_size = len(y_test)\n",
    "            domain_labels = np.concatenate([np.zeros(test_size), np.ones(ood_size)])\n",
    "                    \n",
    "            y_test_norm = normalize_test_labels(y_test)\n",
    "        \n",
    "            values = defaultdict() # metric values for all folds for given algorithm\n",
    "\n",
    "            if mode == \"single\":\n",
    "                # use 0th model from ensemble as a single model\n",
    "                model = load_model(name, alg, 0)\n",
    "                preds = model.predict(test_pool)\n",
    "                preds_proba = model.predict_proba(test_pool)\n",
    "    \n",
    "                values[\"error\"] = (preds != y_test).astype(int)\n",
    "                values[\"nll\"] = nll_class(y_test_norm, preds_proba)\n",
    "                values[\"TU_prr\"] = prr_class(y_test_norm, preds_proba, entropy(preds_proba), False)\n",
    "                values[\"KU_prr\"] = float(\"nan\")\n",
    "                values[\"KU_auc\"] = float(\"nan\")\n",
    "                    \n",
    "                ood_preds_proba = model.predict_proba(ood_test_pool)\n",
    "                in_measure = entropy(preds_proba)\n",
    "                out_measure = entropy(ood_preds_proba)\n",
    "                values[\"TU_auc\"] = ood_detect(domain_labels, in_measure, out_measure, mode=\"ROC\")\n",
    "\n",
    "            if mode == \"ens\":\n",
    "                all_preds = [] # predictions of all models in ensemble\n",
    "                all_preds_ood = []\n",
    "                    \n",
    "                for i in range(num_models):\n",
    "                    model = load_model(name, alg, i)\n",
    "                    preds = model.predict_proba(test_pool)\n",
    "                    all_preds.append(preds)\n",
    "                    preds = model.predict_proba(ood_test_pool)\n",
    "                    all_preds_ood.append(preds) \n",
    "                        \n",
    "                all_preds = np.array(all_preds)\n",
    "                preds_proba = np.mean(all_preds, axis=0)\n",
    "                \n",
    "                all_preds_ood = np.array(all_preds_ood)\n",
    "                \n",
    "                preds = np.argmax(preds_proba, axis=1)\n",
    "                values[\"error\"] = (preds != y_test_norm).astype(int)\n",
    "                values[\"nll\"] = nll_class(y_test_norm, preds_proba)\n",
    "                \n",
    "                TU = entropy_of_expected_class(all_preds)\n",
    "                DU = expected_entropy_class(all_preds)\n",
    "                KU = TU - DU\n",
    "                \n",
    "                TU_ood = entropy_of_expected_class(all_preds_ood)\n",
    "                DU_ood = expected_entropy_class(all_preds_ood)\n",
    "                KU_ood = TU_ood - DU_ood\n",
    "\n",
    "                values[\"TU_prr\"] = prr_class(y_test_norm, preds_proba, TU, False)\n",
    "                values[\"KU_prr\"] = prr_class(y_test_norm, preds_proba, KU, False)\n",
    "                  \n",
    "                values[\"TU_auc\"] = ood_detect(domain_labels, TU, TU_ood, mode=\"ROC\")\n",
    "                values[\"KU_auc\"] = ood_detect(domain_labels, KU, KU_ood, mode=\"ROC\")\n",
    "                        \n",
    "            results.append(values)\n",
    "\n",
    "    return np.array(results)\n",
    "    \n",
    "def make_table(values):\n",
    "    prr_TU = np.array([values[i][\"TU_prr\"] for i in range(len(values))])\n",
    "    auc_TU = np.array([values[i][\"TU_auc\"] for i in range(len(values))])\n",
    "    TU = np.concatenate((prr_TU, 100*auc_TU), axis=0)\n",
    "\n",
    "    prr_KU = np.array([values[i][\"KU_prr\"] for i in range(len(values))])\n",
    "    auc_KU = np.array([values[i][\"KU_auc\"] for i in range(len(values))])\n",
    "    KU = np.concatenate((prr_KU, 100*auc_KU), axis=0)\n",
    "\n",
    "    df = pd.DataFrame(np.stack((TU, KU)), index=['TU', 'KU']) \n",
    "    columns=[('PRR%', 'Single','SGB'),('PRR%', 'Single','SGLB'), ('PRR%', 'Ensemble','SGB'),('PRR%', 'Ensemble','SGLB'), \n",
    "             ('AUC-ROC%', 'Single','SGB'),('AUC-ROC%', 'Single','SGLB'), ('AUC-ROC%', 'Ensemble','SGB'),('AUC-ROC%', 'Ensemble','SGLB')]\n",
    "    df.columns=pd.MultiIndex.from_tuples(columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea3e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tClassification - Boosting\n",
      "\t\t\t===PRR and AUC-ROC Table===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">PRR%</th>\n",
       "      <th colspan=\"4\" halign=\"left\">AUC-ROC%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Single</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ensemble</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Single</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ensemble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "      <th>SGB</th>\n",
       "      <th>SGLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TU</th>\n",
       "      <td>45.305925</td>\n",
       "      <td>46.238564</td>\n",
       "      <td>45.501887</td>\n",
       "      <td>45.858059</td>\n",
       "      <td>78.47836</td>\n",
       "      <td>75.49434</td>\n",
       "      <td>79.607265</td>\n",
       "      <td>75.308638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KU</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.732223</td>\n",
       "      <td>18.123800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.087251</td>\n",
       "      <td>99.484801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRR%                                   AUC-ROC%                       \\\n",
       "       Single              Ensemble               Single             Ensemble   \n",
       "          SGB       SGLB        SGB       SGLB       SGB      SGLB        SGB   \n",
       "TU  45.305925  46.238564  45.501887  45.858059  78.47836  75.49434  79.607265   \n",
       "KU        NaN        NaN  19.732223  18.123800       NaN       NaN  99.087251   \n",
       "\n",
       "               \n",
       "               \n",
       "         SGLB  \n",
       "TU  75.308638  \n",
       "KU  99.484801  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"credit\"\n",
    "\n",
    "print('\\t\\t\\tClassification - Boosting')\n",
    "print(\"\\t\\t\\t===PRR and AUC-ROC Table===\")\n",
    "\n",
    "values = aggregate_results(dataset)\n",
    "\n",
    "make_table(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaca004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
